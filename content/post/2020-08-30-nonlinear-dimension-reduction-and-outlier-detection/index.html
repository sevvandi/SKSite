---
title: Which nonlinear dimension reduction methods can detect outliers inside a sphere?
author: Sevvandi Kandanaarachchi
date: '2020-08-29'
slug: []
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-08-29T12:20:36+10:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>In this post we will look at how well nonlinear dimension reduction techniques detect outliers that are placed inside a sphere, when all the other data points are on the surface of the sphere. We will use the R package <strong>dimRed</strong> for this analysis. First we note that linear project-based methods on the original data will not work, because projections will hide the outliers inside the sphere. Also, none of the nonlinear dimension reduction methods we consider are especially designed for outlier detection. So, it is not a limitation of the method if they do not detect outliers. But, we want to see if any of them do.</p>
<p>Let’s plot the data first.</p>
<pre class="r"><code>set.seed(1)
theta &lt;- seq(from = -1*pi, to = pi, by=0.01)
phi &lt;- seq(from = 0, to= pi*2, by=0.01)
theta1 &lt;- sample(theta, size=5*length(theta), replace=TRUE)
phi1 &lt;- sample(phi, size=5*length(phi), replace=TRUE)
x &lt;- cos(theta1)*cos(phi1)
y &lt;- cos(theta1)*sin(phi1)
z &lt;- sin(theta1)

df &lt;- cbind.data.frame(x,y,z)
df1 &lt;- df
dim(df)</code></pre>
<pre><code>## [1] 3145    3</code></pre>
<pre class="r"><code>oo &lt;- matrix(c(0,0,0,0,0.2,-0.1), nrow=2, byrow = TRUE)
colnames(oo) &lt;- colnames(df)
df &lt;- rbind.data.frame(df, oo)
plot(df[ ,c(1,2)], pch=20)
points(df[3146:3147, ], pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/dataset-1.png" width="672" /></p>
<pre class="r"><code>dd2 &lt;- dimRedData(df)</code></pre>
<p>The dataframe contains 3145 points on the surface of the sphere. These points are non-outliers. The data points in the dataframe on rows 3146 and 3147 are the outliers. We plot the outliers in red and green.</p>
<p>Most methods need a parameter such as <span class="math inline">\(k\)</span> in KNN distances. For all methods we fix <span class="math inline">\(k=10\)</span> and map the original data from <span class="math inline">\(\mathbb{R}^3\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span>. It is also called a 2-dimensional embedding. Let’s start our analysis with IsoMap.</p>
<div id="isomap" class="section level2">
<h2>IsoMap</h2>
<pre class="r"><code>emb2 &lt;- embed(dd2, &quot;Isomap&quot;, .mute = NULL, knn = 10)</code></pre>
<pre><code>## 2020-08-30 20:39:23: Isomap START</code></pre>
<pre><code>## 2020-08-30 20:39:23: constructing knn graph</code></pre>
<pre><code>## 2020-08-30 20:39:23: calculating geodesic distances</code></pre>
<pre><code>## 2020-08-30 20:39:28: Classical Scaling</code></pre>
<pre class="r"><code>embdat &lt;- as.data.frame(emb2@data)
plot(embdat, pch=20,main=&quot;IsoMap embedding&quot;)
points(embdat[3146:3147, ],  pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/isomap-1.png" width="672" /></p>
<p>Well, <span class="math inline">\(k=10\)</span>, did not bring out the outliers inside the sphere using IsoMap. Next, let’s look at Locally Linear Embedding (LLE).</p>
</div>
<div id="lle" class="section level2">
<h2>LLE</h2>
<pre class="r"><code>emb2 &lt;- embed(dd2, &quot;LLE&quot;, knn = 10)</code></pre>
<pre><code>## finding neighbours
## calculating weights
## computing coordinates</code></pre>
<pre class="r"><code>embdat &lt;- as.data.frame(emb2@data)
plot(embdat, pch=20, main=&quot;LLE embedding&quot;)
points(embdat[3146:3147, ], pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/LLEfun-1.png" width="672" /></p>
<p>Next we look at Laplacian Eigenmaps.</p>
</div>
<div id="laplacian-eigenmaps" class="section level2">
<h2>Laplacian Eigenmaps</h2>
<pre class="r"><code>emb2 &lt;- embed(dd2, &quot;LaplacianEigenmaps&quot;, knn = 10)</code></pre>
<pre><code>## 2020-08-30 20:42:38: Creating weight matrix</code></pre>
<pre><code>## 2020-08-30 20:42:39: Eigenvalue decomposition</code></pre>
<pre><code>## Eigenvalues: 5.098969e-03 3.829450e-03 4.537894e-17</code></pre>
<pre><code>## 2020-08-30 20:42:39: DONE</code></pre>
<pre class="r"><code>embdat &lt;- as.data.frame(emb2@data)
plot(embdat, pch=20, main=&quot;Lapacian eigenmaps embedding&quot;)
points(embdat[3146:3147, ], pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/laplace-1.png" width="672" />
This is nice. Laplacian eigenmaps really brought out the outliers using <span class="math inline">\(k=10\)</span>. Next we look at diffusion maps.</p>
</div>
<div id="diffusion-maps" class="section level2">
<h2>Diffusion Maps</h2>
<pre class="r"><code>emb2 &lt;- embed(dd2, &quot;DiffusionMaps&quot;)</code></pre>
<pre><code>## Performing eigendecomposition
## Computing Diffusion Coordinates
## Elapsed time: 47.7 seconds</code></pre>
<pre class="r"><code>embdat &lt;- as.data.frame(emb2@data)
plot(embdat, pch=20, main=&quot;Diffusion maps embedding&quot;)
points(embdat[3146:3147, ],  pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/diffusion-1.png" width="672" /></p>
<p>Diffusion maps also brought out the outliers. Interestingly, everything else is mapped to a line. Next we consider non-metric dimensional scaling.</p>
</div>
<div id="non-metric-dimensional-scaling" class="section level2">
<h2>Non-Metric Dimensional Scaling</h2>
<pre class="r"><code>emb2 &lt;- embed(dd2, &quot;nMDS&quot;, d = function(x) exp(dist(x)))

embdat &lt;- as.data.frame(emb2@data)
plot(embdat, pch=20, main=&quot;non-MDS embedding&quot;)
points(embdat[3146:3147, ], pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/nonmetric-1.png" width="672" /></p>
<p>Finally we do tsne.</p>
</div>
<div id="tsne" class="section level2">
<h2>tsne</h2>
<pre class="r"><code>emb2 &lt;- embed(dd2, &quot;tSNE&quot;, perplexity = 10)

embdat &lt;- as.data.frame(emb2@data)
plot(embdat, pch=20, main=&quot;tsne embedding&quot;)
points(embdat[3146:3147, ], pch=20, col=c(&quot;red&quot;, &quot;green&quot;), cex=2)</code></pre>
<p><img src="/post/2020-08-30-nonlinear-dimension-reduction-and-outlier-detection/index_files/figure-html/tsne-1.png" width="672" /></p>
<p>Of the methods explored, Laplacian eigenmaps brought out the outliers while showing some spherical structure in the embedding. Diffusion maps also brought out the outliers. However, the spherical structure of the data was lost in the embedding.</p>
</div>
