---
title: Anomaly Detection Ensembles
author: Sevvandi Kandanaarachchi
date: '2022-03-16'
slug: []
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2022-03-16T15:50:32+11:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


## What is an anomaly detection ensemble?

It is a bunch of anomaly detection methods put together to get a final anomaly score/prediction. So you have a bunch of methods, and each of these methods have its own anomaly score, which is used by the ensemble to come up with the consensus score. 


What are the ways of constructing an anomaly detection ensemble? Broadly, anomaly detection ensembles can be categorised into 3 camps.

1. Feature bagging
2. Subsampling
3. Using combination functions


## Feature bagging
Feature bagging is a very popular ensemble technique in anomaly detection. Feature bagging uses different attribute subsets to find anomalies. In a dataset, generally observations are denoted by rows and attributes are denoted by columns. Feature bagging considers different column subsets. That is, multiple copies of the same dataset each having a slightly different set of columns is considered. For each dataset copy, we find anomalies using a single anomaly detection method.  Then the anomaly scores are averaged to compute the ensemble score. 

Let us try this with the letter dataset from the [ODDS repository](http://odds.cs.stonybrook.edu/). We first read the dataset and normalize it so that each column has values within 0 and 1. Let's have a loot at the data after normalising.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, message=FALSE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(here)
library(R.matlab)


# Unitize each column of X
unitize <- function(X) {
  for (col in 1:NCOL(X)) {
    maxcol <- max(X[, col])
    mincol <- min(X[, col])
    if(maxcol!= mincol){
      X[, col] <- (X[, col] - mincol) / (maxcol - mincol)
    }
  }
  X
}
```

```{r featurebagging1}
datori <- readMat("letter.mat")
Xori <- datori$X
Xori <- unitize(Xori)
head(Xori)
```

Now, feature bagging would select different column subsets. Let's pick different columns.



```{r featurebagging2}
set.seed(1)
dd <- dim(Xori)[2]
sample_list <- list()
for(i in 1:10){
  sample_list[[i]] <- sample(1:dd, 20)
}
sample_list[[1]]
sample_list[[2]]
```

Next we select the subset of columns in each sample_list and find anomalies in each subsetted-dataset. Let's use the KNN_AGG anomaly detection method. This method aggregates the k-nearest neighbour distances. If a data point has high KNN distances compared to other points, then it is considered anomalous, because it is far away from other points. 

```{r featurebaggin3}
library(DDoutlier)
knn_scores <- matrix(0, nrow = NROW(Xori), ncol = 10)
for(i in 1:10){
  knn_scores[ ,i] <- KNN_AGG(Xori[ ,sample_list[[i]]])
}
head(knn_scores)

```

Now we have the anomaly scores for the 10 subsetted-datasets. In feature bagging the general method of consensus is to add up the scores or take the mean of the scores, which is an equivalent thing to do. 

```{r featurebagging4}
bagged_score <- apply(knn_scores, 1, mean)
```

We can compare the bagged anomaly scores with the anomaly scores f we didn't use bagging. That is, if we used the full dataset, what would be anomaly scores? Does bagging make it better?  For this we need the labels/ground truth. To evaluate the performance, we use the area under the ROC curve.

```{r featurebagging5}
library(pROC)
labels <- datori$y[ ,1]

# anomaly scores without feature bagging - taking the full dataset
knn_agg_without <- KNN_AGG(Xori)

# ROC  - without bagging
rocobj1 <- roc(labels, knn_agg_without, direction = "<")
rocobj1$auc

rocobj2 <- roc(labels, bagged_score, direction = "<")
rocobj2$auc
```
Yes! We see that there is an increase in AUC (area under the ROC curve) by feature bagging. In this case it is a small improvement. But, nonetheless there is an improvement.


## Subsampling
Subsampling uses different subsets of observations to come up with anomaly scores. Instead of columns, here we use different subsets of observations. Then we average the anomaly scores to get an ensemble score. First, let's get the different observation samples.  For this, we will use non-anomalous observations because the anomalous observations are rare, we don't want to use all of them. 

```{r subsampling1}
set.seed(1)
sample_matrix <- matrix(0, nrow = NROW(Xori), ncol = 10)
inds0 <- which(labels == 0)
nn1 <- sum(inds0)
inds1 <- which(labels == 1)
nn2 <- sum(inds1)
sample_matrix[inds1, ] <- 1
for(j in 1:10){
  sam <- sample(inds0, 1400)
  sample_matrix[sam, j] <- 1
}
head(sample_matrix)
```

Our sample_matrix contains 1 if that observation is going to be used and 0 if it doesn't. We are going to use 10 subsampling iterations.

Now that we have our subsamples, let's use an anomaly detection method to get the anomaly scores.

```{r subsampling2}
anom_scores <- matrix(NA, nrow = NROW(Xori), ncol = 10)
for(j in 1:10){
  inds <- which(sample_matrix[ ,j] == 1)
  Xsub <- Xori[inds, ]
  anom_scores[inds,j] <- KNN_AGG(Xsub)
}
head(anom_scores)
```

We see there are NA values when that observation was not selected. Now we will get the mean anomaly score. But some observations did not got selected for certain iterations. We need to take that into account. 

```{r subsampling3}
rowsum <- apply(sample_matrix, 1, sum)
subsampled_score <- apply(anom_scores, 1, function(x) sum(x, na.rm = TRUE))/rowsum
head(subsampled_score)
```

Here, we have divided the sum of the anom_scores by the number of times each observation was selected. The ensemble score is subsampled_score.  Now we can see if the ensemble score is better than the original score. 

```{r subsampling4}
# ROC  - without bagging
rocobj1 <- roc(labels, knn_agg_without, direction = "<")
rocobj1$auc

rocobj2 <- roc(labels, subsampled_score, direction = "<")
rocobj2$auc

```
Oh dear! Not really for this example. But it doesn't go down by much, which is a relief. Sometimes the ensemble is not better than the original model.  But most of the time it is. That is why we use ensembles. 
